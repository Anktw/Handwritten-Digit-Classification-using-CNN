{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ratna-Babu/Handwritten-Digit-Classification-using-CNN/blob/main/Handwritten_Digit_Classification_usingCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PcMKZkHkGz1L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Invert the colors of the images\n",
        "x_train = 255 - x_train\n",
        "x_test = 255 - x_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7vqiCOf0IMGR"
      },
      "outputs": [],
      "source": [
        "# Preprocessing the Images\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Reshape the images to include the channel dimension\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3Y0tFtw5INOh"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tdJsfYALIQG5"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5hZOpzSIRNj",
        "outputId": "69f20a04-16b5-49bb-f3f5-21ae5563f792"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 167ms/step - accuracy: 0.7631 - loss: 0.8423 - val_accuracy: 0.9724 - val_loss: 0.0955\n",
            "Epoch 2/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 162ms/step - accuracy: 0.9729 - loss: 0.0858 - val_accuracy: 0.9795 - val_loss: 0.0687\n",
            "Epoch 3/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 163ms/step - accuracy: 0.9834 - loss: 0.0571 - val_accuracy: 0.9854 - val_loss: 0.0514\n",
            "Epoch 4/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 165ms/step - accuracy: 0.9873 - loss: 0.0445 - val_accuracy: 0.9861 - val_loss: 0.0473\n",
            "Epoch 5/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 165ms/step - accuracy: 0.9887 - loss: 0.0360 - val_accuracy: 0.9862 - val_loss: 0.0443\n",
            "Epoch 6/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 162ms/step - accuracy: 0.9924 - loss: 0.0263 - val_accuracy: 0.9861 - val_loss: 0.0488\n",
            "Epoch 7/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 168ms/step - accuracy: 0.9928 - loss: 0.0233 - val_accuracy: 0.9869 - val_loss: 0.0406\n",
            "Epoch 8/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 172ms/step - accuracy: 0.9937 - loss: 0.0203 - val_accuracy: 0.9892 - val_loss: 0.0387\n",
            "Epoch 9/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 162ms/step - accuracy: 0.9949 - loss: 0.0156 - val_accuracy: 0.9884 - val_loss: 0.0438\n",
            "Epoch 10/10\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 163ms/step - accuracy: 0.9954 - loss: 0.0144 - val_accuracy: 0.9900 - val_loss: 0.0380\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=200, validation_split=0.2)\n",
        "model.save('mnist_cnn.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeq84lkuITcx",
        "outputId": "87d7bee0-8b5f-4b90-81af-1f67714a4963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9900\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test accuracy: {score[1]:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "TYZpcbuBSf-M",
        "outputId": "63d0a1bf-38f8-4cae-a53a-e4ca1864622c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Image file not found at 2.png\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('mnist_cnn.h5')\n",
        "\n",
        "def predict_digit(image_path):\n",
        "    try:\n",
        "        # Load and preprocess the image\n",
        "        img = Image.open(image_path).convert('L')\n",
        "        img = img.resize((28, 28))\n",
        "        img_array = np.array(img)\n",
        "        img_array = 255 - img_array\n",
        "        img_array = img_array.astype('float32') / 255.0\n",
        "        img_array = img_array.reshape(1, 28, 28, 1)\n",
        "\n",
        "        # Make the prediction\n",
        "        prediction = model.predict(img_array)\n",
        "        predicted_digit = np.argmax(prediction)\n",
        "        confidence = np.max(prediction)\n",
        "\n",
        "        display_prediction(image_path, predicted_digit, confidence)\n",
        "\n",
        "        return predicted_digit\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Image file not found at {image_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "def display_prediction(image_path, digit, confidence):\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    img_resized = cv2.resize(img, (500, 500))\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    label = f'Predicted: {digit} ({confidence:.2f})'\n",
        "    cv2.putText(img_rgb, label, (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    plt.imshow(img_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "image_path = '2.png'  # Replace with the actual path to your image\n",
        "predicted_digit = predict_digit(image_path)\n",
        "\n",
        "if predicted_digit is not None:\n",
        "    print(f\"Predicted digit: {predicted_digit}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOg3OoqhvhAE3SDkNeZQ6HB",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
